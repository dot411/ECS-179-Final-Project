## Movement/Physics - Sween Zhou
My main approach to movement/physics is using area2D to track interactions, and raycasts for checking line of sights, directions, and interest weights. The basic movement and collisions are Godot’s physics.

### Unit Movement
I essentially made it so that all physical entities are treated as Obj (they are inherited from the Obj class). Unit extends HP_Obj extends Obj. The idea is that all units are just objects with health and movement functions. A UnitController (Player or UnitAI) is assigned to pass the input commands. There’s also an AbilityController that handles ability casting separately. The unit controller can send request to the unit to move, select item, spend resources, interact(), bind ability to the ability controller, and cast abilities. The player controller is really simple because it takes the input directly from the keys and mouse. For the AI, I had to think of a way so that they don’t just blindly chase the player and end up getting clumped together. I was using a raycast system to make them steer and spread (inspired by [youtube](https://www.youtube.com/watch?v=6BrZryMz-ac&t=65s) and [context steering](https://www.gameaipro.com/GameAIPro2/GameAIPro2_Chapter18_Context_Steering_Behavior-Driven_Steering_at_the_Macro_Scale.pdf)). The idea is that you can generate an interest map array for directions and modify the weights to determine which direction is the most desirable. If there’s a potential target nearby (such as the player), you can draw a vector from the unit to that target and compute the interest using the dot and cross product between the goal vector and each of the raycast vectors. The dot product yields forward or backward interest (cosine angle), and the cross product yields sideward interest (sine angle). I added a chase_coefficient (range from -1.0 to 1.0) and a surround_coefficient (0.0 to 1.0) to define how much a unit would like to chase, retreat or move in tangent direction. For example, if chase_coefficient is set to negative, it will favor backward movement. Using the same idea, if there are allies nearby, it will compute the dot products and decrease the interests of the raycast vectors based on how much they are aligned with the directions to the allies. The same is true if there are obstacles nearby. There’s also a distance factor. So the farther the nearby objects are from the unit, the less impact they’ll have on the interest_map. For sideward movement, I also used a steer_state control. It’s an integer of either 1 or -1. The steer_state is used to determine whether the unit should steer clockwise or counter-clockwise. One problem with sideward movement is that the unit might start to jitter if it changes steer_state too frequently, which is very likely to occur when there are multiple objects close by. This problem was solved by adding a steer_state_cooldown. The cooldown makes it so that the unit can only change its steer_state once a in while.

|   |   |   |
|---|---|---|
| <img src="https://github.com/dot411/ECS-179-Final-Project-Documentation/blob/main/images/AI1.gif" width="100%"> | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/AI2.gif" width="100%"> | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/AI3.gif" width="100%"> |

The AI will only engage with the player when aggroed. If it’s idle, it will wander within a defined radius. To make the wander look smooth, I was using simplex noise to determine the wander direction. The noise makes it so that the randomness of the selected direction are incremented relative to each iteration. Wander still uses the same interest_map and detects obstacles and nearby allies. The only difference here is that it takes the vector to the wander’s center point as the goal direction instead of the vector to a target. The farther away the unit is from the center, the more the home vector will take effect on the interest_map. Also, the AI only remembers the last position where it has seen the target. If the player run behinds obstacles, the AI will stop steering and take the fastest path to the corner to try to catch up. If the target still can’t be found around the corner, the AI will go back to wander mode.

|   |   |
|---|---|
| <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/wander.gif" width="100%"> | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/AI4.gif" width="100%"> |

### Property Editable System
I wanted to separate the property variables from the normal gameplay class variables and methods. The idea is that variables can be exported and stored in a .tres resource file so that they can be edited in the inspector. Every obj essentially consists of three files, a .tscn (scene), a .gd (script), and a .tres (resource). The default Resource class only exports the variables as they are but doesn’t account for interrelationships across the editable variables (for example, turning a boolean variable to true to display more properties, embedding a button in inspector that resets all properties, etc.). So, I made a BaseData class and overrode the base getter, setter, and _get_property_list() functions. Variables can still be exported via the @export tag, but properties in general are stored in a properties dictionary. The purpose is so that other data classes can extend BaseData, put a @tool tag at the top to make it run during editor time, and define the relationships between properties by calling the base functions in BaseData (loop_properties() of a dictionary, nested dictionary, or display individual properties; defining how a property must be displayed in the inspector and its editing constraints through hint and hint_string; accessing and storing a property via a property path string, clear_property() like removing nested properties, erase_property(), etc.). BaseData is also the base class for the trigger system. The base Trigger class can read methods and arguments automatically from a given script (target_class.new()) and export these functions as a dropdown menu. The idea is that variables should be treated as functions instead of explicit values. For example, the value of an integer is the returning value of integer.run(). So, in the inspector, you can dynamically make a function’s argument dependent on other variables (such as a caster’s run-time attack/ability power). This property editable system and the idea of triggers were initially inspired from a long time ago by Warcraft 3’s map editor.

Abilities and Effects:
|   |   |
|---|---|
| Everything can be edited via the inspector. An ability’s mechanics is defined through the channeling track. The basic idea is that you can insert channeling intervals to the track, and for each interval, you can assign a channeling time and effects that will be triggered when the interval finishes. I borrowed this idea from Godot’s AnimationPlayer. The idea of a track is so that you can time the effects and arrange them in a progressive order. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/ability_inspector1.png" width=200> |
| A melee attack, for example, is just an ability that spawns damage effect regions. The spawn effects are called position effects. The distance and angle modifier will determine the position of the effect relative to the casting center. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/interval_inspector1.png" width=200> |
| If the follow_parent parameter in EffectRegionData is on, spawning this effect region will use the caster’s position as the casting center, and the computation with the distance modifier won’t be affected by the aim position. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/long_range_melee1.gif" width=500> |
| If follow_parent is turned off, it will cast the effect as if the caster is standing at the aim position. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/long_range_melee2.gif" width=500> |
| Visualized effect regions would look like this. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/long_range_melee_visual.gif" width=500> |
| Using multiple intervals. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/progressive_melee.gif" width=500> |
| Turning on some of the parameters in EffectRegionData such as wait_for_collision_to_trigger will allow the effect region to persist and only trigger on collision. This setup can be used for traps and projectiles. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/effect_region_inspector1.gif" width=200> |
| Taking projectile as an example, a projectile is essentially a controller that moves the EffectRegion. If the effect region’s one_shot is turned off, the projectile will pierce through enemies. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/pierce_projectile.gif" width=500> |
| Using the same idea with multiple intervals on the ability’s channeling track, projectile spread can look like this. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/projectile_spread1.gif" width=500> |

Triggers:  
All effects are triggers. There are three types of effects, SelfEffect, AreaEffect, and PositionEffect. For a melee attack, the position effect spawns an effect region, and the effect region uses an AreaEffect to deal damage to the units (or other HP_Obj such as destructibles). The base Obj class has an apply_effect() function. This function will run the effect trigger to call the specified function from the target script (usually the object’s own class).
|   |   |
|---|---|
| In the effect trigger, when a function is selected, the arguments will be loaded to the inspector. Most functions’ arguments are also triggers, so further options will show up. For example, if the function is take_damage, the argument would be a float value, and FloatPoint is another nested trigger. You can select raw_value function to simply use it numerically as a normal float or you can customize the value’s definition by selecting options such as arithmetics or unit_attribute. Using unit_attribute, for example, will make the FloatPoint trigger search for the specified trigger unit and take the return value from that unit’s attribute using a multiplier and a modifier. The problem, then, is that the trigger unit is only a concept. It’s impossible to know who’s going to be the caster because the game hasn’t even started. So, this TriggerUnit is another Trigger. All we need is to give it a function, such as triggering_caster. The triggers will call the run() function (which is essentially a getter function) and passing a TriggerBuffer during the gameplay to recursively run through the trigger functions. The return value from the run() will be passed back to the objects to apply the effects. The idea of values as run functions was also partly inspired back then when I learned that Godot’s scripts are treated as interpretation objects. So, essentially, a trigger is like an exported version of script. | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/editing_effect.gif" width=200> |

Trigger Editables:  
The base Obj class has a state control(data.active/inactive). Trigger editables are used to control activation/deactivation events and special actions such as send_game_message() and transitioning to a new map. A TriggerEditable is made of an exported Event trigger and an exported array of Action triggers. Trigger editables are mostly just for managing triggers on placable entities. For example, putting an Interactable on top of a Destrutible and adding a trigger editable can make the destructible destroy (deactivate) on interaction (when the player presses e near an interactable, it will change state between active/inactive). Setting the requires_resources parameter of an interactable can yield, for example, a locked container or door, or a resource exchange object if it contains items in its give_inventory list. The destructible can also drop PickableItem on the ground if it has items. AbilityObject can randomly cast position effects within a certain radius (a simplified version of UnitAI). Ability object is used to spawn units, projectiles, and effect regions. Adding a trigger editable on top of an ability object can make it so that, for example, on entering the next level, disable all the current unit spawners in the current level.
|   |   |
|---|---|
| <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/ability_obj_data_inspector.png" width=200> | <img src="https://github.com/dot411/ECS-179-Final-Project/blob/main/Project%20Documentation-Sween/images/using_trigger_editable.gif" width=200> |

Lastly, we only have basic items, abilities, interactions in the actual game because we didn’t have enough time to coordinate the levels and datas.